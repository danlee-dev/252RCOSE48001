from typing import List, Optional, Any, Dict
from fastapi import APIRouter, Depends, UploadFile, File, status, HTTPException, Header
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import desc, func
from app.core.database import get_db, AsyncSessionLocal
from app.schemas.contract import ContractResponse, ContractDetailResponse
from app.api import deps
from app.models.user import User
from app.models.contract import Contract 
from app.utils.file_storage import save_contract_file 
from app.core.celery_app import celery_app 
import requests
import asyncio
import os
import sys
from elasticsearch import Elasticsearch
from neo4j import Driver, basic_auth
from sentence_transformers import SentenceTransformer
import numpy as np
from app.api.deps import verify_internal_api_key, get_es_client, get_neo4j_driver
import re 
from app.tasks.analysis_tasks import analyze_contract_task 
# ğŸ”´ [FDE IMPORT] FDE ê´€ë ¨ í´ë˜ìŠ¤/í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (main.pyê°€ ê²½ë¡œë¥¼ ì„¤ì •í•œë‹¤ê³  ê°€ì •)
from ai.preprocessing.fde_generator import ( 
    FixedDimensionalEncodingConfig,
    generate_query_fde,
    EncodingType,
    ProjectionType,
)


router = APIRouter()

# --- Helper Class for Splitting (3_embed_muvera.pyì˜ ë¡œì§ í†µí•©) ---
class APISentenceSplitter:
    @staticmethod
    def split_sentences(text: str, min_length: int = 10) -> List[str]:
        sentences = re.split(r'[.!?]\s+', text)
        sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) >= min_length]
        if not sentences:
            sentences = [text]
        return sentences
# -------------------------------------------------------------------


# ğŸ’¡ ëª¨ë¸ ë° FDE ì„¤ì • (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ)
try:
    GLOBAL_EMBEDDING_MODEL = SentenceTransformer("nlpai-lab/KURE-v1")
    GLOBAL_EMBEDDING_MODEL.max_seq_length = 512
    EMBEDDING_DIM = GLOBAL_EMBEDDING_MODEL.get_sentence_embedding_dimension() 
    
    # ğŸ”´ [FDE ì„¤ì •] 3_embed_muvera.pyì˜ ì„¤ì • (1024ì°¨ì›) ë°˜ì˜
    FDE_CONFIG = FixedDimensionalEncodingConfig(
        dimension=EMBEDDING_DIM,
        num_repetitions=1, 
        num_simhash_projections=3, 
        seed=42,
        encoding_type=EncodingType.AVERAGE, # ë¬¸ì„œ ìƒì„±ì— AVERAGE ì‚¬ìš©ë˜ì—ˆìœ¼ë¯€ë¡œ ì¿¼ë¦¬ë„ AVERAGE ì„¤ì • ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•¨
        projection_type=ProjectionType.DEFAULT_IDENTITY,
        final_projection_dimension=1024 
    )
    
except Exception as e:
    print(f"âŒ Embedding Model Load Failed: {e}")
    GLOBAL_EMBEDDING_MODEL = None
    FDE_CONFIG = None
    
INDEX_NAME = "docscanner_chunks"


# -------------------------------------------------------------------------
# ğŸ”´ [FastAPI ë¼ìš°í„°] ë©”ì¸ BE ë¡œì§ (ì—…ë¡œë“œ ë° ì¡°íšŒ ìœ ì§€)
# -------------------------------------------------------------------------

@router.post("/", status_code=202, summary="ê³„ì•½ì„œ ì—…ë¡œë“œ ë° AI ë¶„ì„ ì‹œì‘")
async def upload_contract(
    file: UploadFile = File(..., description="ì—…ë¡œë“œí•  PDF íŒŒì¼"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user)
):
    """
    **[ë³´í˜¸ë¨]** PDF ê³„ì•½ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , Celery Task Queueì— AI ë¶„ì„ ì‘ì—…ì„ ë“±ë¡í•©ë‹ˆë‹¤.
    
    ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” íŒŒì¼ ì €ì¥ í›„ ì¦‰ì‹œ ì‘ë‹µ(202 Accepted)í•˜ë©°, AI ë¶„ì„ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    
    - **ìš”ì²­ íŒŒë¼ë¯¸í„° (Input):**
        - `file`: ì—…ë¡œë“œí•  **PDF íŒŒì¼** (multipart/form-dataë¡œ ì „ì†¡). í˜„ì¬ 10MB ì´í•˜ ê¶Œì¥.
    - **ìš”ì²­ í—¤ë”:**
        - `Authorization`: `Bearer <Access Token>` (ë¡œê·¸ì¸ í•„ìˆ˜)
    - **ì„±ê³µ ì‘ë‹µ (202 Accepted):**
        - `message`: ì‘ì—… ì ‘ìˆ˜ í™•ì¸
        - `contract_id`: ìƒˆë¡œ ìƒì„±ëœ ê³„ì•½ì„œì˜ DB ID
        - `status`: PENDING (ì²˜ë¦¬ ëŒ€ê¸° ì¤‘)
    - **ì£¼ìš” ì˜¤ë¥˜ ì½”ë“œ:**
        - `401 Unauthorized`: ìœ íš¨í•˜ì§€ ì•Šì€ í† í°
        - `400 Bad Request`: íŒŒì¼ í˜•ì‹ì´ PDFê°€ ì•„ë‹˜
        - `500 Internal Server Error`: íŒŒì¼ ì‹œìŠ¤í…œ ì €ì¥ ì˜¤ë¥˜, Celery ë“±ë¡ ì˜¤ë¥˜ ë“±
    """
    # 1. íŒŒì¼ ì €ì¥ ë¡œì§ ì‹¤í–‰
    try:
        file_url = await save_contract_file(current_user.id, file)
    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì €ì¥ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
    # 2. DBì— ê³„ì•½ì„œ ì •ë³´ ì €ì¥ (status: PENDING)
    new_contract = Contract(
        user_id=current_user.id,
        title=file.filename,
        file_url=file_url,
        status="PENDING"
    )
    db.add(new_contract)
    await db.commit()
    await db.refresh(new_contract)
    
    # 3. Celery Taskì— ì‘ì—… ë“±ë¡
    analyze_contract_task.delay(new_contract.id) 
    
    return {
        "message": "Accepted", 
        "contract_id": new_contract.id, 
        "status": new_contract.status
    }

@router.get("/", response_model=List[ContractResponse], summary="ë‚´ ê³„ì•½ì„œ ëª©ë¡ ì¡°íšŒ")
async def read_contracts(
    skip: int = 0, 
    limit: int = 10, 
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user)
):
    """
    **[ë³´í˜¸ë¨]** í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ëª¨ë“  ê³„ì•½ì„œì˜ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤. 
    ê²°ê³¼ëŠ” í˜ì´ì§€ë„¤ì´ì…˜ì„ ì§€ì›í•˜ë©°, **ì—…ë¡œë“œ ìµœì‹ ìˆœ**ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤.
    
    - **ìš”ì²­ íŒŒë¼ë¯¸í„° (Query):**
        - `skip`: ê±´ë„ˆë›¸ í•­ëª© ìˆ˜ (í˜ì´ì§€ë„¤ì´ì…˜ ì˜¤í”„ì…‹, ê¸°ë³¸ê°’ 0).
        - `limit`: í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìµœëŒ€ í•­ëª© ìˆ˜ (í˜ì´ì§€ í¬ê¸°, ê¸°ë³¸ê°’ 10).
    - **ì‘ë‹µ (Output):**
        - `200 OK`: ê³„ì•½ì„œ ID, ì œëª©, ìƒíƒœ, ìœ„í—˜ë„ ë ˆë²¨ ë“± í•µì‹¬ ì •ë³´ ëª©ë¡.
    - **ì£¼ìš” ì˜¤ë¥˜ ì½”ë“œ:**
        - `401 Unauthorized`: ìœ íš¨í•˜ì§€ ì•Šì€ í† í°.
    """
    # ìµœì‹  ê³„ì•½ì„œê°€ ëª©ë¡ ë§¨ ì•ì— ì˜¤ë„ë¡ created_atì„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ(DESC) ì •ë ¬í•©ë‹ˆë‹¤.
    stmt = (
        select(Contract)
        .where(Contract.user_id == current_user.id)
        .order_by(desc(Contract.created_at))
        .offset(skip)
        .limit(limit)
    )
    
    # DBì—ì„œ ë°ì´í„° ì‹¤í–‰
    result = await db.execute(stmt)
    contracts = result.scalars().all() 
    
    return contracts

# -------------------------------------------------------------------------
# ğŸ”´ [íˆ´ API] Difyê°€ í˜¸ì¶œí•  ì»¤ìŠ¤í…€ íˆ´ API ë¡œì§ êµ¬í˜„
# -------------------------------------------------------------------------
    
# Muvera ê²€ìƒ‰ íˆ´ (ES RRF ê¸°ë°˜)
@router.get("/v1/search-muvera", 
            summary="Dify Tool: Muvera ë©€í‹° ë²¡í„° ê²€ìƒ‰", 
            include_in_schema=False, # ğŸ‘ˆ ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œ ê¸ˆì§€
            status_code=status.HTTP_200_OK)
async def search_muvera(
    query_text: str, 
    es: Elasticsearch = Depends(get_es_client), 
    internal_api_key: str = Depends(verify_internal_api_key)
):
    """
    **[ë‚´ë¶€ ì „ìš© API]** (Difyê°€ í˜¸ì¶œ) ì‚¬ìš©ìì˜ ì¡°í•­ì„ FDE ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ESì—ì„œ ìœ ì‚¬ ì¡°í•­ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    - **ì‚¬ìš© ì£¼ì²´:** Dify AI Agent
    - **ì…ë ¥:** `query_text` (LLMì´ ì¶”ì¶œí•œ ê³„ì•½ ì¡°í•­ í…ìŠ¤íŠ¸)
    - **ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:** `{"context": [{"source": "...", "text": "..."}]}`
    - **ì¸ì¦:** `X-Internal-API-Key` í—¤ë” í•„ìš”.
    """
    if GLOBAL_EMBEDDING_MODEL is None or FDE_CONFIG is None:
        raise HTTPException(status_code=503, detail="Embedding model or FDE config not loaded.")
        
    # 1. ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ FDE ë²¡í„°ë¡œ ë³€í™˜ (MUVERA ë¡œì§ ì ìš©)
    try:
        # ë¬¸ì¥ ë¶„í•  
        sentences = APISentenceSplitter.split_sentences(query_text)
        
        # ê° ë¬¸ì¥ ì„ë² ë”©
        sentence_embeddings = GLOBAL_EMBEDDING_MODEL.encode(
            sentences, 
            convert_to_numpy=True, 
            normalize_embeddings=True
        )
        
        # ğŸ”´ [í•µì‹¬] FDEë¡œ ì••ì¶• (generate_query_fde ì‚¬ìš©)
        query_vector_fde = generate_query_fde(sentence_embeddings, FDE_CONFIG)
        query_vector = query_vector_fde.tolist() 
        
    except Exception as e:
        print(f"Query FDE generation failed: {e}")
        raise HTTPException(status_code=500, detail="ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì‹¤íŒ¨")
    
    # 2. Elasticsearch KNN ê²€ìƒ‰ ì¿¼ë¦¬
    search_query = {
        "field": "embedding",
        "k": 5, 
        "num_candidates": 50,
        "query_vector": query_vector, 
        "filter": {"bool": {"must_not": [{"exists": {"field": "type"}}]}},
    }
    
    try:
        # 3. ES ê²€ìƒ‰ ì‹¤í–‰
        response = es.search(
            index=INDEX_NAME,
            knn=search_query,
            _source=["text", "source", "doc_type"], 
            size=5
        )
        
        # 4. ê²°ê³¼ íŒŒì‹± (Dify Context í˜•ì‹ì— ë§ì¶¤)
        context = []
        for hit in response['hits']['hits']:
            source = hit['_source']
            context.append({
                "source": f"{source.get('source', 'N/A')}/{source.get('doc_type', 'N/A')}",
                "text": source['text']
            })
            
        return {"context": context}
        
    except Exception as e:
        print(f"ES search failed: {e}")
        raise HTTPException(status_code=500, detail="Elasticsearch ê²€ìƒ‰ ì‹¤íŒ¨")


# GraphDB ìœ„í—˜ ê·œì¹™ ê²€ìƒ‰ íˆ´
@router.get("/v1/search-risk-pattern", 
            summary="Dify Tool: GraphDB ìœ„í—˜ ê·œì¹™ ê²€ìƒ‰", 
            include_in_schema=False, # ğŸ‘ˆ ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œ ê¸ˆì§€
            status_code=status.HTTP_200_OK)
async def search_risk_pattern(
    query_text: str, 
    driver: Driver = Depends(get_neo4j_driver),
    internal_api_key: str = Depends(verify_internal_api_key)
):
    """ 
    **[ë‚´ë¶€ ì „ìš© API]** ì‚¬ìš©ìì˜ ì¡°í•­ê³¼ ê´€ë ¨ëœ ë²•ë¥  ì§€ì‹ ê·¸ë˜í”„(Neo4j)ì—ì„œ
    ìœ„í—˜ íŒ¨í„´, ê·œì¹™, ë²•ë ¹ ê´€ê³„ ë“±ì„ ê²€ìƒ‰í•˜ëŠ” ì»¤ìŠ¤í…€ íˆ´ì…ë‹ˆë‹¤.
    
    - **ì‚¬ìš© ì£¼ì²´:** Dify AI Agent
    - **ì…ë ¥:** `query_text` (LLMì´ ì¶”ì¶œí•œ ê³„ì•½ ì¡°í•­ í…ìŠ¤íŠ¸)
    - **ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:** `{"context": [{"rule_name": "...", "text": "..."}]}`
    - **ì¸ì¦:** `X-Internal-API-Key` í—¤ë” í•„ìš”.
    """
    
    # 1. 7_seed_ontology.pyì— ì •ì˜ëœ Regex ê¸°ë°˜ ê²€ìƒ‰ ë¡œì§ ì‚¬ìš©
    cypher_query = """
    // ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ë‹¨ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ RiskPattern ë…¸ë“œë¥¼ ê²€ìƒ‰
    MATCH (r:RiskPattern)
    WHERE ANY(trigger IN r.triggers WHERE toLower($queryText) CONTAINS toLower(trigger))
    OPTIONAL MATCH (r)-[:IS_A_TYPE_OF]->(c:ClauseType)
    RETURN r.name AS name, r.explanation AS explanation, r.riskLevel AS level, c.name AS clauseType
    """
    
    try:
        # Neo4j ì„¸ì…˜ ì—´ê¸° (basic_authë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ê²° ì¸ì¦)
        with driver.session(auth=basic_auth(os.getenv("NEO4J_USER"), os.getenv("NEO4J_PASSWORD"))) as session:
            result = session.run(cypher_query, queryText=query_text).data()
            
            # 2. ê²°ê³¼ íŒŒì‹± (Dify Context í˜•ì‹ì— ë§ì¶¤)
            context = []
            for record in result:
                context.append({
                    "rule_name": record['name'],
                    "text": f"ìœ„í—˜ íŒ¨í„´ '{record['name']}' ({record['clauseType']} ì¡°í•­, ìœ„í—˜ë„: {record['level']}): {record['explanation']}"
                })
            
            # 3. ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì„ì‹œ ë©”ì‹œì§€ ë°˜í™˜
            if not context:
                return {"context": [{"text": "ê²€ìƒ‰ëœ ìœ„í—˜ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤."}]}
            
            return {"context": context}
            
    except Exception as e:
        print(f"Neo4j search failed: {e}")
        raise HTTPException(status_code=500, detail="GraphDB ê²€ìƒ‰ ì‹¤íŒ¨")